# Pipeline de Dados com Python, PostgreSQL e Power BI

Este projeto tem como objetivo criar uma pipeline de dados para processar, validar e armazenar dados de um arquivo CSV, preparando-os para consumo no Power BI. Utilizamos ferramentas como  **Pandas**,  **Pandas Profiling**,  **Pydantic**,  **Streamlit**  e  **PostgreSQL**  para garantir a qualidade e integridade dos dados.

----------

## Sum√°rio

1.  Vis√£o Geral do Projeto
    
2.  Ferramentas e Bibliotecas Utilizadas
    
3.  Etapas do Projeto
    
4.  Diagrama de Arquitetura
    
5.  Como Executar o Projeto
    
6.  Documenta√ß√£o das Bibliotecas
    
7.  Contribui√ß√£o
    
8.  Licen√ßa
    

----------

## Vis√£o Geral do Projeto

O projeto consiste em uma pipeline de dados que realiza as seguintes etapas:

1.  **Leitura e An√°lise Explorat√≥ria de Dados (EDA)**: Utilizamos o  **Pandas Profiling**  para identificar problemas como valores faltantes, outliers e inconsist√™ncias.
    
2.  **Valida√ß√£o de Dados**: Com o  **Pydantic**, definimos um esquema de valida√ß√£o para garantir a integridade dos dados. Uma aplica√ß√£o interativa foi criada com  **Streamlit**  para facilitar a valida√ß√£o.
    
3.  **Limpeza e Transforma√ß√£o**: Os dados s√£o limpos e transformados usando  **Pandas**, corrigindo problemas identificados na etapa de EDA.
    
4.  **Armazenamento no PostgreSQL**: Os dados processados s√£o armazenados em um banco de dados  **PostgreSQL**  para persist√™ncia e consulta.
    
5.  **Consumo no Power BI**: O Power BI se conecta ao PostgreSQL para criar visualiza√ß√µes e dashboards.
    

----------

## Ferramentas e Bibliotecas Utilizadas

-   **Python**: Linguagem de programa√ß√£o principal.
    
-   **Pandas**: Manipula√ß√£o e an√°lise de dados.
    
-   **Pandas Profiling**: Gera√ß√£o de relat√≥rios de an√°lise explorat√≥ria.
    
-   **Pydantic**: Valida√ß√£o de dados baseada em esquemas.
    
-   **Streamlit**: Cria√ß√£o de uma aplica√ß√£o web para valida√ß√£o interativa de dados.
    
-   **PostgreSQL**: Banco de dados relacional para armazenamento dos dados processados.
    
-   **Power BI**: Ferramenta de visualiza√ß√£o e an√°lise de dados.
    

----------

## Etapas do Projeto

1.  **Pr√©-Processamento**:
    
    -   Leitura do arquivo CSV com  **Pandas**.
        
    -   An√°lise explorat√≥ria com  **Pandas Profiling**.
        
    -   Valida√ß√£o interativa com  **Streamlit**.
        
2.  **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)**:
    
    -   Defini√ß√£o do esquema de dados com  **Pydantic**.
        
    -   Limpeza e transforma√ß√£o dos dados com  **Pandas**.
        
    -   Carga dos dados processados no  **PostgreSQL**.
        
3.  **Consumo**:
    
    -   Conex√£o do  **Power BI**  ao PostgreSQL para visualiza√ß√£o dos dados.
        

----------

## Diagrama de Arquitetura

Abaixo est√° o diagrama de arquitetura do projeto:

````mermaid 
---
config:
  theme: default
  look: classic
  layout: elk
---
flowchart TD
    A["üìÅ Arquivo CSV"] --> B["üîç An√°lise Explorat√≥ria (Pandas Profiling)"]
    B --> C["‚úÖ Valida√ß√£o de Dados (Streamlit + Pydantic)"]
    C --> D["üßπ Limpeza e Transforma√ß√£o (Pandas)"]
    D --> E["üíæ Armazenamento no PostgreSQL"]
    E --> F["üìä Consumo no Power BI"]
    C -- üö´ Erros de Valida√ß√£o --> G["üìù Relat√≥rio de Erros"]
    G --> A
````

----------

## Como Executar o Projeto

### Pr√©-requisitos

-   Python 3.8 ou superior.
    
-   PostgreSQL instalado e configurado.
    
-   Power BI Desktop (opcional, para visualiza√ß√£o).
    

### Passos para Execu√ß√£o

1.  **Clone o reposit√≥rio**:

````bash
    git clone https://github.com/seu-usuario/nome-do-repositorio.git
    cd nome-do-repositorio
````

2.  **Configure o ambiente virtual**:
```bash    
    python -m venv venv
    source venv/bin/activate  # No Windows use `venv\Scripts\activate`
```    
3.  **Instale as depend√™ncias**:
```bash    
    pip install -r requirements.txt
```    
4.  **Execute a aplica√ß√£o de valida√ß√£o com Streamlit**:
```bash    
    streamlit run app_validacao.py
```    
5.  **Conecte-se ao PostgreSQL**: *(SER√Å CONSTRUIDO EM BREVE)*
    
    -   Configure as credenciais do banco de dados no arquivo  `config.py`.
        
    -   Execute o script de carga no PostgreSQL:
    ````bash         
        python carregar_postgres.py
    ````    
6.  **Conecte o Power BI ao PostgreSQL**: 
    
    -   Use as credenciais do banco de dados para se conectar e criar visualiza√ß√µes.
        

----------

## Documenta√ß√£o das Bibliotecas

Aqui est√£o os links para a documenta√ß√£o das bibliotecas utilizadas:

-   [Pandas](https://pandas.pydata.org/docs/)
    
-   [Pandas Profiling](https://pandas-profiling.ydata.ai/docs/master/)
    
-   [Pydantic](https://docs.pydantic.dev/latest/)
    
-   [Streamlit](https://docs.streamlit.io/)
    
-   [PostgreSQL](https://www.postgresql.org/docs/)
    
-   [Power BI](https://learn.microsoft.com/en-us/power-bi/)
    

----------

## Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Siga os passos abaixo:

1.  Fa√ßa um fork do reposit√≥rio.
    
2.  Crie uma branch para sua feature (`git checkout -b feature/nova-feature`).
    
3.  Commit suas mudan√ßas (`git commit -m 'Adicionando nova feature'`).
    
4.  Push para a branch (`git push origin feature/nova-feature`).
    
5.  Abra um Pull Request.
    

----------

## Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT. Veja o arquivo  [LICENSE](https://license/)  para mais detalhes.


‚≠êÔ∏è From [Maria Benussy]([https://github.com/seu-username](https://github.com/MBON-py))